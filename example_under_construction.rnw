% Created 2018-02-29 
% Modified 2018-04-15
\documentclass[11pt]{article}
\usepackage[a4paper,portrait,textwidth=18cm]{geometry}

\usepackage[titletoc]{appendix}
\setcounter{secnumdepth}{2}

%% INCLUDE FOLLOWING BLOCK FOR BIBLIOGRAPHY
\usepackage[
backend=biber,
style=alphabetic,
citestyle=authoryear]{biblatex}
\renewcommand*{\bibopenparen}{[}
\renewcommand*{\bibcloseparen}{]}
\renewcommand*{\finalandcomma}{,}
\renewcommand*{\finalnamedelim}{, and~}
\renewcommand*\bibnamedash{\rule[0.48ex]{3em}{0.14ex}\space}
\addbibresource{example_under_construction.bib} 
\RequirePackage{listings}
\lstset{language=Python}

\begin{document}


\begin{titlepage}
\centering
{\scshape\LARGE University College Cork\par}
\vspace{1cm}
{\scshape\Large Master's Thesis \par}
\vspace{1.5cm}
{\huge\bfseries Pedestrian Action Recognition\par}  
\vspace{0.5cm}
{\Large\bfseries Classification and tracking \par}
\vspace{2cm}
{\Large\itshape Dhanya Sringeri Jayachandra \par}
\vfill
supervised by\par
Dr. Gregory Provan
\vfill
{\large \today\par}
\end{titlepage}

\setcounter{tocdepth}{2}
\tableofcontents
\clearpage
\listoftables
\listoffigures
\clearpage

\section{Abstract}

In this paper, we will discuss and try to classify pedestrians from cyclists as accurately and quickly as possible. Accuracy and Speed are both very important aspects that could highly influence the outcome in road-safety systems. Various types of Convolutional Neural Networks approches will be applied and we can compare the advantages of one model over the other. Improving accuray of object detection and tracking are our main goal.
\clearpage

\section{Introduction}

Road-Safety is a crucial requirement in all Autonomous and Advanced Driver Assistance systems. The smart
cars are facing many challenges in Vulnerable road users recognition [ VRUs]. The objects infront of the car in traffic scene must be
detected with high accuracy to achieve fully autonomous cars. The detection of object of interest is hard in urban areas,
because of the wide variety of object appreances and occlusions caused by other objects. The similarities of object of interest with other or to the background and physical effects like cast shadows or reflections can make the distinction difficult. [cite: Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art]. We have seen examples of Computer Vision failing to recognize cyclists, and failure in recognizing pedestrians in dim light.  Though most
autonomous cars are able to classify pedestrians, it would largely help us deal with the cyclists differently.
Vulnerable road users can be detected using 2 methods.\\
(1) Sensor based approach\\
(2)Vision based approach\\

\subsection{Vision based approach:}
In vision based approach only data from the cameras are used to distinguish between objects.
Computer vision means the machine is able to get some meaningful information from an image or video. Human vision is highly
developed with the ability to understand and classify the whole scene at once, However, it was a difficult problem to gain decent 
vision results with computers up until recently, as the computers did not have the processing abilities. Though, the concept of computer vision has
been around since the 1950's, only recently we have been able to practically implement these theories. Thanks to huge volumes of 
images and videos available online. The advance in hardware with high processing power GPUs is another reason for the recent success 
which is a contributuion from the gaming industry.\\

The object detection task can be addressed with a variety of different of sensors. Cameras are the cheapest and most commonly used type of sensors for the detection of ob-
jects. The visible spectrum (VS) is typically used for daytime detections whereas the infrared spectrum can be used for night-time detection. Thermal infrared (TIR) cameras capture relative temperature which allows to distinguish warm objects like pedestrians from cold objects like vegetation or the road.[cite: Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art]


\subsection{Sensor based approach:}
In sensor based approach, the autonomous vehicles are mounted with sensors such as LiDAR systems.
The depth information of the sensor based systems result in higher accuracy in detecting an object and localizing it. These are considered supe-
rior and known to have high accuaracy in today’s research field.Depending on the weather conditions or material properties it can be problematic
to rely on a single type of sensor alone. Visible spectrum cameras and laser scanners are affected by reflective or transparent surfaces while
hot objects (like engines) or warm temperatures can influence
Thermal infrared cameras. [cite: Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art]. A combination of sensors would be the most apt method to 
generate high accuracy results.(Enzweiler, M., & Gavrila, D. M. (2011). A multilevel mixture-of-experts
framework for pedestrian classification. IEEE Trans. on Image Processing
(TIP), 20, 2967–2979.); [Chen, X., Kundu, K., Zhu, Y., Ma, H., Fidler, S., & Urtasun, R. (2016b). 3d
object proposals using stereo imagery for accurate object class detection.
arXiv.org, 1608.07711.][González, A., Vázquez, D., Lóopez, A. M., & Amores, J. (2016). On-board ob-
ject detection: Multicue, multimodal, and multiview random forest of local
experts. IEEE Trans. on Cybernetics, .]  These papers allow mention in depth about robust methods for sensor fusion. Sensors are also expensive and some car manufacturers are reluctant to compramise the look of the car for smart features.\\

In this paper, we will discuss and try to identify cyclists as accurately and quickly as possible using
vision based approach. Accuracy and Speed are both very important aspects that could highly influence the
outcome in road-safety systems. In this papers, we will compare the performance of different Convolutional
neural network architectures, their performance on the vision-based networks. We can compare the perfor-
mance of one model over the other. Improving accuray of object detection with each new network tried is
the goal.

\section{Literature Review}

Brief history of computer vision in Autonomous cars:

Around the time of 1992 - 2000 statistical machine learning models such as Support Vector Machine, Boosting started to gain popularity. The VJ detector by Viola-Jones [tobecitedcitexiaofei li new 2016] with it's detection technology was the first ground-breaking object detection algorithm, which was able to detected faces with limited amount of computational power available at the time.

SIFT model by David Lowe, 1999 feature based object detection. The idea is to match the features of 2 images that are constant or invariant. Based on these features the objects were classified into that particular class. This is a more efficient method than pattern matching the whole image. Spatial Pyramid matching, there are certain patterns in the image, that will hint us about what the image could be about. A varitation of this model is Histogram of Gradients[HoG], [cite: Dalal and Trings 2005] and Deformable part Model [cite: Felzenswalb, McAllester, Ramnam, 2009] performed well on Human detection. 

In 2012, Convolutional neural networks[cite: Alex Krizhevsky, Ilya Sutskever, Geoffery E Hilton, 2012] out-performed all the other models significantly in the annual Image-net object recognition challenge, which is the bench-mark dataset for object recognition. 


As we are following a vision based object detection approach using using 2-D images, Convolutional neural networks are the obvious solution. They have outperformed all the previous
detection methods by significant margins. There are various variations of convolutional neural networks to choose from based on the problem at hand. We will try to work with few variations of CNNs.

\subsection{Detection}

The common methods followed during any traffic scene detections are,\\
1)Preprocessing the images\\
2)Extracting region of interest\\
3)Object classification\\
4)Verification\\

\subsubsection{1.Preprocessing of images}

\subsubsection{2.Extracting region of interest}

\subsubsection{3.Object classification}

\subsubsection{4.Verification}





\subsection{Convolutional neural networks}

Computer vision approach in detecting vulnerable road users 

Brief:\\
Convolutional neural networks were introduced in 2014, ever since then they have been able to produce phenomenol results in the field of computer vision.
These are often the most sought after method while trying to solve any object detection or localization tasks. 

 ever since then they have bet all the previous meth-
ods in terms of object detection. In 2014, R-CNN [Regional Convolutional neural network] won the imagenet
challenge by a significant margin compared to previous methods. It used a region proposal method on the
image, then each proposed region was fed to seperate CNN and finally the object was detected.
Fast-RCNN introduced using the regional proposal method on the feature map that was extractred by
the CNN, hence saving a lot of computation time. Faster-RCNN as we have used in this model, uses it’s
own region proposal method based on the values computed by during the feature map generator instead of
using an external regional proposal algorithm. This makes the system 100 times faster than RCNN.
Faster RCNN consists of 2 parts:
(1)Feature Extractor\\
(2)Region Proposal network\\
\subsubsection{Feature Extractor}:
The feature extractor localises the parts of the image based on features. Some of the popular feature
extractors are VGGnet, Resnet and Inception. So far, Resnet is known to have the highest accuracy. It is
a very deep model with 101 hidden layers. Due to gradient explosion problem, it was impossible to have
such deep layers up until the invention of Resnet. Resnet won the imagenet object detection challenge in
2015, beating other competitors in the field by significant margin. We will be using Resnet as our feature
extractor in our model.\\
\subsection{Region Proposal network}:
Another CNN model that is considered in this setting is,
Faster Region based convolutional neural networks:\\
\section{Datasets}

The dataset that is considered in this experiment is available for public as tsinga-dailmer dataset/

\section{Experiment}:
I have divided the dataset of cyclists in 3 different views. Narrow, Intermediate and wide based on the
aspect ratio of the bounding box of cyclists. It’s important to train the network on the different views of
cyclists seperately as the cyclists look completely different from different views.

\subsection{Parameter optimization}
Stride size: Reduced the stride size from 16 to 8, even though the computation time is longer, more
information needs to processed.\\

\subsection{Region Proposal network}
Region proposal networks generate proposals from the image fed to the network which might contain
the object. So, RPN is responsible for the network to decide if an object is in foreground or background.
In the first stage anchor generator, I am reducing the stride, so that more regions are proposed and none of
the small cyclists are missed out.
I have 4 anchors of scales 0.25, 0.5, 0.75 and 1.0. Each anchor will have 3 boxes with aspect ratio of
1:1(Intermidiate), 1:2(Narrow view), 2:1(Wide view).
The maximum number of box proposals from the first stage was changed to 300. Used drop-out to
avoid overfitting of the neurons and improve accuracy. Drop out increases the number of possible iterations
required to converge. Hence, we increase the number of iterations.\\

\subsection{Regularization:}
Regularization modifies the objective function that we minimize by adding additional terms that penalize
large weights. In other words, we change the objective function so that it becomes Error+f(), where f()
grows larger as the components of grow larger and is the regularization strength (a hyper-parameter for
the learning algorithm).\\

\subsection{L2 Regularization}
It can be implemented by augmenting the error function with the squared magnitude of all weights in
the neural network. In other words, for every weight w in the neural network, we add 1/2 w**2 to the
error function. The L2 regularization has the intuitive interpretation of heavily penalizing ”peaky” weight
vectors and preferring diffuse weight vectors. This has the appealing property of encouraging the network
to use all of its inputs a little rather than using only some of its inputs a lot. Of particular note is that dur-
ing the gradient descent update, using the L2 regularization ultimately means that every weight is decayed
linearly to zero. Because of this phenomenon, L2 regularization is also commonly referred to as weight decay.\\

\subsection{Hard negative mining}

\subsection{Hyper-parameter tuning}

\subsubsection{R-FCN network:}
RFCN pretrained on Coco image dataset is used. This is a much bigger imageset with 1.5 million images. Using this model
the training period reduced drastically.
This network is used with blah blah
\section{Accuracy}

\begin{center}
 \begin{tabular}{||c c c c||} 
 \hline
 Model & Modifications & Narrow & Intermediate & Wide \\ [0.5ex] 
 \hline
FasterRCNN +Resnet & No finetuning & 53.2 & 22 & 787 \\ 
 \hline
FasterRCNN +Resnet & Increased region proposals & 55 & 33 & 5415 \\
 \hline
FasterRCNN + Resnet & dropout & 59 & 32 & -\\
 \hline
 R-FCN + Resnet & No finetuning & 50 & 33 & -\\
 \hline

 \hline
\end{tabular}
\end{center}




\section{Future work:}

We could calculate the distance between car and cyclists to determine if any action must be taken. We could also conduct the same experiments mentioned above in dim light and night time environments to understand how well the models would perform under challenging circumstances.

\printbibliography

\end{document}